# Replace `[...]`, `[MODEL_DST]`, `[DATA_DST]`, `[DATA_DST_librilight]` with appropriate paths
--runname=am_transformer_s2s_librivox
--rundir=[...]
--archdir=[...]
--arch=am_arch/am_transformer_s2s_librivox.arch
--tokensdir=[MODEL_DST]/am
--tokens=librispeech-train-all-unigram-10000.tokens
--lexicon=[MODEL_DST]/am/librispeech-train+dev-unigram-10000-nbest10.lexicon
--train=[DATA_DST]/lists/train-clean-100.lst,[DATA_DST]/lists/train-clean-360.lst,[DATA_DST]/lists/train-other-500.lst,[DATA_DST_librilight]/lists/librilight.lst
--valid=dev-clean:[DATA_DST]/lists/dev-clean.lst,dev-other:[DATA_DST]/lists/dev-other.lst
--mfsc
--usewordpiece=true
--wordseparator=_
--criterion=transformer
--am_decoder_tr_dropout=0.1
--am_decoder_tr_layerdrop=0.1
--am_decoder_tr_layers=6
--maxdecoderoutputlen=120
--labelsmooth=0.05
--dataorder=output_spiral
--inputbinsize=25
--attnWindow=softPretrain
--softwstd=4
--trainWithWindow=true
--pretrainWindow=1
--attention=keyvalue
--encoderdim=512
--memstepsize=5000000
--eostoken=true
--pcttraineval=1
--pctteacherforcing=99
--sampletarget=0.01
--netoptim=adagrad
--critoptim=adagrad
--lr=0.03
--lrcrit=0.03
--lr_decay=2
--warmup=64000
--linseg=0
--momentum=0.0
--maxgradnorm=0.1
--onorm=target
--sqnorm
--nthread=6
--batchsize=4
--filterbanks=80
--minloglevel=0
--reportiters=1000
--logtostderr
--enable_distributed
